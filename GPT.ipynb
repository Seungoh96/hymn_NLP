{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-06 11:21:59--  https://raw.githubusercontent.com/Seungoh96/hymn_NLP/main/dataset/hymn_dataset.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 548649 (536K) [text/plain]\n",
      "Saving to: 'hymn_dataset.txt.1'\n",
      "\n",
      "hymn_dataset.txt.1  100%[===================>] 535.79K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2024-05-06 11:21:59 (7.78 MB/s) - 'hymn_dataset.txt.1' saved [548649/548649]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the dataset to train the model \n",
    "!wget https://raw.githubusercontent.com/Seungoh96/hymn_NLP/main/dataset/hymn_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it \n",
    "with open('hymn_dataset.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  227391\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만복의 근원 하나님\n",
      "온 백성 찬송 드리고\n",
      "저 천사여 찬송하세\n",
      "성부 성자 성령 -아멘찬양 성부 성자 성령\n",
      "성 삼위 일체께\n",
      "영원무궁하기까지 영광을 돌리세\n",
      "영광을 돌리세 아멘성부 성자와 성령\n",
      "찬송과 영광 돌려보내세\n",
      "태초로 지금까지 또 영원무궁토록\n",
      "성 삼위께 영광 영광 아멘성부 성자와 성령\n",
      "영원히 영광 받으옵소서\n",
      "태초로 지금까지 또 영원무궁토록\n",
      "성 삼위께 영광 아\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 1000 characters\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Vocabulary in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (),-./123456:=]gins~ –가각간갇갈감갑값갓갔강갖같갚개거걱건걷걸검겁것게겐겔겟겠겨격견결겸겼경곁계고곡곤곧골곱곳공과관광괴교구국군굳굴굶굽궁권궐궤귀귐귓그극근글금급긋긍기긴길김깃깊까깝깨깰꺼껏께껴꼬꼭꼴꽂꽃꾀꾸꾼꿀꿇꿈꿔끄끊끌끓끗끝끼낀낄낌나낙난날남납낫났낭낮낯낱낳내낸낼냄냇냉냐너넉넌널넓넘넣네녀녁년념녔녕녘노녹논놀농높놓뇌뇨누눈눌눕눠뉘느늑는늘능늦늪니닌닐님다닥닦단닫달닭닮담답닷당닻닿대댈더덕던덤덩덮데덴도독돋돌돔돕동돼됐되된될됨됩두둔둘둠둡둥둬뒀뒤드득든듣들듬듭듯등디딜딪따딴딸땀땅때떠떡떤떨떻떼뗍또뚜뚝뚫뛰뜨뜬뜰뜻띄띠라락란랄람랍랐랑래랫랭랴략량러럭런럼럽렀렁렇레렌렐렘려력련렬렴렵렷렸령례로록론롬롭롱뢰뢸룁료루룩룬룰룻뤄뤘류륜륭르른를름릅릇릎리린릴림립마막만많말맑맘맙맛망맞맡매맥맨맬맹맺머먹먼멀멈멍메멘며면멸명모목몫몬몰몸몹못묘무묵묶문묻물뭇뭉뭐므미민믿밀및밑바박밖반받발밝밟밤방밭배백밸뱃버벅번벌범법벗베벼벽변별병볕보복본볼봄봅봉봐뵈뵐뵙부북분불붉붓붙브비빈빌빎빕빗빚빛빠빨빼뺏뻐뻗뻤뼈뼉뿌뿐쁘쁜쁠쁨삐사삭산살삶삼삽샀상새샘샛생샤서석선설섬섭섰성세센셀셈셔셨소속손솔솜솟송쇠수숙순술숨숭숯숲쉬쉰쉴쉼쉽스슨슬슴습승시식신싣실싫심십싶싸싹싼쌀쌈쌍쌓써썩쏘쏟쓰쓴쓸씀씌씨씩씻씽아악안앉않알앓암압앗았앙앞애앨야약양얕얘어억언얹얻얼얽엄업없엇었엎에엔엘엠여역연열염엽엿였영옅옆예옛오옥온올옮옳옴옵옷옹와완왔왕왜외요욕욥용우욱운울움웁웃웅워원월웠웬위윗유육율으윽은을음응의이익인일읽잃임입잇있잉잊잎자작잔잖잘잠잡장재쟁저적전절젊점접정젖제젠져졌조족존졸좁종좋좌죄죠주죽준줄줍중줘즉즐증지직진질짐집짓징짖짙짜짝짧쩌쩔쪽쫓찌찍찔찢차착찬찮찰참찼창찾채책처척천철첨첩청체쳐쳤초촛총최추축춘출춤충춰췄취측치친칠침칩칭캄캐커컫케켜켰코쾌크큰키킨킬킴타탁탄탈탐탑탕태택터털토통투툼퉁트특튼틀틈티파팎판팔패퍼펴편펼평폐포폭표푸푼풀품풍프픈플픔피핀필핍핏핑하한할함합항해햇했행향허헌험헛헤헬헴혀현혈협형혜혠호혹혼홀홉홍화확환활황횃회획효후훈훌휘휩휼흉흐흑흔흘흙흠흡흥희흰히힌힐힘\n",
      "895\n"
     ]
    }
   ],
   "source": [
    "# All the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mapping from characters to integers \n",
    "```a={}```\n",
    "creates a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[557, 165, 1, 834, 493, 621]\n",
      "안녕 하세요\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"안녕 하세요\"))\n",
    "print(decode(encode(\"안녕 하세요\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([227391]) torch.int64\n",
      "tensor([346, 429, 649,   1,  90, 634,   1, 834, 132, 192,   0, 607,   1, 411,\n",
      "        492,   1, 729, 505,   1, 240, 339,  61,   0, 673,   1, 740, 471, 592,\n",
      "          1, 729, 505, 834, 493,   0, 492, 439,   1, 492, 663,   1, 492, 310,\n",
      "          1,   5, 555, 369, 729, 572,   1, 492, 439,   1, 492, 663,   1, 492,\n",
      "        310,   0, 492,   1, 476, 638,   1, 653, 745, 108,   0, 600, 634, 383,\n",
      "         81, 834,  96, 102, 706,   1, 600,  71, 646,   1, 220, 339, 493,   0,\n",
      "        600,  71, 646,   1, 220, 339, 493,   1, 555, 369, 492, 439,   1, 492,\n",
      "        663, 615,   1, 492, 310,   0, 729, 505,  69,   1, 600,  71,   1, 220,\n",
      "        302, 428, 145, 493,   0, 790, 748, 312,   1, 706,  92, 102, 706,   1,\n",
      "        265,   1, 600, 634, 383,  81, 794, 313,   0, 492,   1, 476, 638, 108,\n",
      "          1, 600,  71,   1, 600,  71,   1, 555, 369, 492, 439,   1, 492, 663,\n",
      "        615,   1, 492, 310,   0, 600, 634, 891,   1, 600,  71,   1, 403, 643,\n",
      "        612, 499, 485,   0, 790, 748, 312,   1, 706,  92, 102, 706,   1, 265,\n",
      "          1, 600, 634, 383,  81, 794, 313,   0, 492,   1, 476, 638, 108,   1,\n",
      "        600,  71,   1, 555, 369, 650,   1, 740, 706,  26,   1, 346, 388, 244,\n",
      "        555,   0, 429,   1, 696, 526, 184,   1, 696,   1, 592, 859, 615,   0,\n",
      "        675, 186,   1, 492, 439,   1, 492, 663,   1, 492, 310,   0, 729, 505,\n",
      "        834,  61,   1, 729, 505, 834, 493,   1, 555, 369, 375, 499, 339,   1,\n",
      "        172, 592, 485,   1, 696,   1, 729, 572,   1, 834, 592, 276,   0, 600,\n",
      "         71,  69,   1,  82, 493, 615,   1, 688,  85, 615,   1, 638, 582, 646,\n",
      "          0, 607,   1, 176, 339,   1, 193, 520, 339, 526, 184,   0, 346, 618,\n",
      "        649,   1, 618, 108,   1, 220, 302, 276,   1, 555, 369, 492, 439,   1,\n",
      "        492, 663,   1, 492, 310,   1, 476, 638, 653, 745, 108,   0, 657, 646,\n",
      "          1, 374, 555,   1, 729, 572,   1,  58, 410,   1, 240, 339, 493,   0,\n",
      "        790, 748, 439, 792,   1, 706,  92, 102, 706,   1, 265,   1, 600, 634,\n",
      "        794, 313,   0, 600,  71,   1, 600,  71,   1, 555, 369,   2,   8,   3,\n",
      "         39, 323,   1,  39, 323,   1,  39, 323,   1, 675, 186, 834, 528,   1,\n",
      "        696, 192,   0, 650, 333,   1, 555, 765,   1, 625, 339,   1, 696, 334,\n",
      "          1, 729, 505,   1, 838, 189, 193,   0,  39, 323,   1,  39, 323,   1,\n",
      "         39, 323,   1, 663, 447, 834, 528,   1, 696, 192,   0, 492,   1, 476,\n",
      "        638, 653, 745,   1, 625, 339,   1, 696, 312, 193,   0,   0,   2,   9,\n",
      "          3,  39, 323,   1,  39, 323,   1,  39, 323,   1, 696, 649,   1, 428,\n",
      "        693,   1, 567, 588,   0, 374, 242,   1, 492, 217,   1, 371, 329,  70,\n",
      "        646,   1, 420, 575,   1, 240, 339, 159,   0, 740,  76, 740, 471,   1,\n",
      "        374, 231,   1, 696, 108,   1,  78, 429, 834, 189,   0, 600, 634, 891,\n",
      "          1, 638, 588,   1,  60, 528,   1, 696, 312, 193])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch \n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets \n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([346, 429, 649,   1,  90, 634,   1, 834, 132])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 \n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([346]) the target: 429\n",
      "when input is tensor([346, 429]) the target: 649\n",
      "when input is tensor([346, 429, 649]) the target: 1\n",
      "when input is tensor([346, 429, 649,   1]) the target: 90\n",
      "when input is tensor([346, 429, 649,   1,  90]) the target: 634\n",
      "when input is tensor([346, 429, 649,   1,  90, 634]) the target: 1\n",
      "when input is tensor([346, 429, 649,   1,  90, 634,   1]) the target: 834\n",
      "when input is tensor([346, 429, 649,   1,  90, 634,   1, 834]) the target: 132\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[399, 280,   1, 439, 251, 764,   1, 257],\n",
      "        [834, 370,   1, 859, 473, 132,   1, 729],\n",
      "        [834,  51, 159,   0, 132,   1, 500, 694],\n",
      "        [226, 528,   1, 696,   1, 132,   1, 729]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[280,   1, 439, 251, 764,   1, 257,   0],\n",
      "        [370,   1, 859, 473, 132,   1, 729, 505],\n",
      "        [ 51, 159,   0, 132,   1, 500, 694,   1],\n",
      "        [528,   1, 696,   1, 132,   1, 729, 572]])\n",
      "----\n",
      "when input is [399] the target: 280\n",
      "when input is [399, 280] the target: 1\n",
      "when input is [399, 280, 1] the target: 439\n",
      "when input is [399, 280, 1, 439] the target: 251\n",
      "when input is [399, 280, 1, 439, 251] the target: 764\n",
      "when input is [399, 280, 1, 439, 251, 764] the target: 1\n",
      "when input is [399, 280, 1, 439, 251, 764, 1] the target: 257\n",
      "when input is [399, 280, 1, 439, 251, 764, 1, 257] the target: 0\n",
      "when input is [834] the target: 370\n",
      "when input is [834, 370] the target: 1\n",
      "when input is [834, 370, 1] the target: 859\n",
      "when input is [834, 370, 1, 859] the target: 473\n",
      "when input is [834, 370, 1, 859, 473] the target: 132\n",
      "when input is [834, 370, 1, 859, 473, 132] the target: 1\n",
      "when input is [834, 370, 1, 859, 473, 132, 1] the target: 729\n",
      "when input is [834, 370, 1, 859, 473, 132, 1, 729] the target: 505\n",
      "when input is [834] the target: 51\n",
      "when input is [834, 51] the target: 159\n",
      "when input is [834, 51, 159] the target: 0\n",
      "when input is [834, 51, 159, 0] the target: 132\n",
      "when input is [834, 51, 159, 0, 132] the target: 1\n",
      "when input is [834, 51, 159, 0, 132, 1] the target: 500\n",
      "when input is [834, 51, 159, 0, 132, 1, 500] the target: 694\n",
      "when input is [834, 51, 159, 0, 132, 1, 500, 694] the target: 1\n",
      "when input is [226] the target: 528\n",
      "when input is [226, 528] the target: 1\n",
      "when input is [226, 528, 1] the target: 696\n",
      "when input is [226, 528, 1, 696] the target: 1\n",
      "when input is [226, 528, 1, 696, 1] the target: 132\n",
      "when input is [226, 528, 1, 696, 1, 132] the target: 1\n",
      "when input is [226, 528, 1, 696, 1, 132, 1] the target: 729\n",
      "when input is [226, 528, 1, 696, 1, 132, 1, 729] the target: 572\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model\n",
    "### Breakdown \n",
    "You first have to embed each token in your input. This means that you are embedding each token with a vector of dimension that matches your vocab size. \n",
    "You do that through ```nn.Embedding()```; with ```nn.Embedding```, you create a matrix that is of size (vocab x vocab). \\\\\n",
    "Now, after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8842, grad_fn=<SelectBackward0>)\n",
      "tensor(280)\n",
      "torch.Size([32, 895])\n",
      "tensor(7.1132, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "흠\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers \n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None: \n",
    "            loss = None\n",
    "        else: \n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step \n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from the distribution\n",
    "            \n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append sampled index to the running sequence \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=1)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zeros_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
